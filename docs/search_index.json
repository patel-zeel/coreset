[["index.html", "IN792: Coresets Coresets1 Preface", " IN792: Coresets Zeel B Patel 2021-03-29 Coresets1 Preface This is a report generated for work done in IN-792 project with Prof. Anirban Dasgupta in Semester-II of academic year 2020-2021. "],["coresets.html", "Coresets2 Coresets 2.1 What are coresets?", " Coresets2 Coresets 2.1 What are coresets? A very nicely written definition of coresets is the following, Coresets are small, weighted summaries of large data sets such that solutions found on the summary itself are provably competitive with solutions found on the full data set. Coresets are extremely useful for models that do not scale well with data. If a model can not be optimized further on time-complexity, using coresets is natural option to cope up with training time. Theoretical guerantee is a unique property about coresets over other approximation techniques, which makes it robust for practical usage. In next chapter we shall see practical introduction to coresets for KMeans. "],["coresets-for-kmeans-intuitive-theory.html", "Coresets3 Coresets for KMeans (intuitive theory) 3.1 Problem formulation 3.2 Uniform sampling 3.3 Importance sampling", " Coresets3 Coresets for KMeans (intuitive theory) 3.1 Problem formulation In a KMeans clustering problem, we want to cluster the dataset \\(X \\in R^d\\) of cardinality \\(N\\) in \\(K\\) seperate clusters. If \\(Q\\) is a set of cluster centers for KMeans in this problem, we can define the cost as following, \\[ cost(X, Q) = \\sum\\limits_{x\\in X}\\min\\limits_{q\\in Q}||x-q||^2_2 \\] If \\(C\\) of cardinality \\(N&#39;\\) is a weighted coreset constructed from dataset \\(X\\), \\(N&#39;&lt;&lt;N\\) is our desired property. \\(C\\) is a valid \\(\\varepsilon\\)-coreset of \\(X\\) if the following property holds for any \\(Q\\) with high probability (can be quantified), \\[ |cost(X, Q) - cost(C,Q)| \\le \\varepsilon cost(X,Q) \\] There is an another consequence of the above theorem which is more useful in practice. If \\(Q^*_X\\) is optimal cluster centers obtained by executing KMeans on full dataset \\(X\\) and \\(Q^*_C\\) is optimal cluster centers obtained by executing KMeans on coreset \\(C\\), the following property holds with high probability, \\[ cost(X,Q^*_X) \\le cost(X, Q^*_C) \\le \\frac{1+\\varepsilon}{1-\\varepsilon}cost(X, Q^*_X) \\] Note that, in practice, computing \\(Q^*_X\\) is not feasible thus we are willing bear a higher cost upto \\(\\frac{1+\\varepsilon}{1-\\varepsilon}cost(X, Q^*_X)\\) at benefit of reduced computational time. This property ensures that cost on the coreset stays within the defined upper bound without actually need of computing \\(Q^*_X\\) (which is obvious but just being explicit). Now, the question is how to construct the coreset \\(C\\) such that above properties hold with high probability (yes, that is important. Nothing is deterministic in the probabilistic world). Let us test a naive way first. 3.2 Uniform sampling 3.3 Importance sampling In the next chapter, we will actually implement the coresets for KMeans clustering step by step. "],["coresets-for-kmeans-pracical.html", "Coresets4 Coresets for KMeans (Pracical)", " Coresets4 Coresets for KMeans (Pracical) Let us import some packages first, from sklearn.cluster import KMeans from sklearn.datasets import make_blobs import matplotlib.pyplot as plt import numpy as np from scipy.spatial.distance import cdist, pdist "]]
