# Coresets

## What are coresets?
A well-explained definition of coresets is the following by @bachem2017practical,

* Coresets are small, weighted summaries of large data sets such that solutions found on the summary itself are provably competitive with solutions found on the full data set.

More intuitively, a coreset is a small sample of the larger data (with weights associated with each data point) that can represent the original data with a good approximation on a particular model/algorithm. 

Coresets are extremely useful for models that do not scale well with data. If a model can not be optimized further on time-complexity, using coresets is natural option to cope up with training time. Theoretical guarantee is a unique property about coresets over other approximation techniques, which makes it robust for practical usage.

In next chapter we shall see the introduction to coresets for the KMeans clustering algorithm.